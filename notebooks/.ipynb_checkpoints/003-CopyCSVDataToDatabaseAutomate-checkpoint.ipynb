{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca16de9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "507bb720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are trying to automate 002 part\n",
    "import pandas as pd \n",
    "import os\n",
    "import numpy as np \n",
    "import psycopg2 as pg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3fd4942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001-ImportCSVtoDfToDatabase.ipynb       003-CopyCSVDataToDatabaseAutomate.ipynb\r\n",
      "002-ImportCSVToDatabaseAutomate.ipynb   customer_contracts.csv\r\n"
     ]
    }
   ],
   "source": [
    "# Find file in directory\n",
    "!ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "132c8c91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['csv_import_functions.py',\n",
       " 'Customer Contracts$.csv',\n",
       " 'Customer Demo.csv',\n",
       " 'Customer Engagements.csv',\n",
       " 'survey_results_public.csv',\n",
       " 'survey_results_schema.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find file in current dir\n",
    "# look for csv and ignore others\n",
    "# make a new directory \n",
    "# move csv file new directory\n",
    "os.listdir('../data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b12ee33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Customer Contracts$.csv',\n",
       " 'Customer Demo.csv',\n",
       " 'Customer Engagements.csv',\n",
       " 'customer_contracts.csv']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_files = []\n",
    "for file in os.listdir(os.getcwd()):\n",
    "    if file.endswith('.csv'):\n",
    "        csv_files.append(file)  \n",
    "\n",
    "csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b67d51ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir datasets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: datasets: File exists\n"
     ]
    }
   ],
   "source": [
    "# Create new dir and move csv file\n",
    "dataset_dir = 'datasets'\n",
    "#create bash command to create dir\n",
    "# mkdir datasets\n",
    "# mkdir = 'mkdir {0}'.format(dataset_dir)\n",
    "#to run bash command \n",
    "try:\n",
    "    mkdir = 'mkdir {0}'.format(dataset_dir)\n",
    "    os.system(mkdir)\n",
    "    print(mkdir)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0568f7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mv 'Customer Contracts$.csv' datasets\n",
      "mv 'Customer Demo.csv' datasets\n",
      "mv 'Customer Engagements.csv' datasets\n",
      "mv 'customer_contracts.csv' datasets\n"
     ]
    }
   ],
   "source": [
    "# move file to new directory\n",
    "# mv file dir\n",
    "for csv in csv_files:\n",
    "    mv_files = \"mv '{0}' {1}\".format(csv, dataset_dir)\n",
    "    print(mv_files)\n",
    "    os.system(mv_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f1bf44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gaurnitai/Desktop/Programming/Python/DataScience/yt/py-database/notebooks/datasets/\n"
     ]
    }
   ],
   "source": [
    "# Create df from CSV file\n",
    "file_path = os.getcwd()+'/'+dataset_dir+'/'\n",
    "print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3e3bd794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer Contracts$.csv\n",
      "Customer Demo.csv\n",
      "Customer Engagements.csv\n",
      "customer_contracts.csv\n"
     ]
    }
   ],
   "source": [
    "data_frames = {}\n",
    "for file in csv_files:\n",
    "    try:\n",
    "        data_frames[file] = pd.read_csv(file_path+file)\n",
    "    except UnicodeDecodeError:\n",
    "        df[file] = pd.read_csv(file_path+file, encoding='ISO-8859-1')\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b12b329e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_name</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>contract_amount_m</th>\n",
       "      <th>invoice_sent</th>\n",
       "      <th>paid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nike</td>\n",
       "      <td>01-02-2019</td>\n",
       "      <td>12-20-2020</td>\n",
       "      <td>2.98</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reebox</td>\n",
       "      <td>06-20-2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.90</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adidas</td>\n",
       "      <td>12-07-2015</td>\n",
       "      <td>6-20-2018</td>\n",
       "      <td>4.82</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Google</td>\n",
       "      <td>05-25-2014</td>\n",
       "      <td>03-20-2017</td>\n",
       "      <td>5.74</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amazon</td>\n",
       "      <td>11-10-2012</td>\n",
       "      <td>12-20-2015</td>\n",
       "      <td>6.66</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>04-29-2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.58</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Apple</td>\n",
       "      <td>10-15-2009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.50</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Airbnb</td>\n",
       "      <td>04-02-2008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.42</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nest</td>\n",
       "      <td>09-19-2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Canon</td>\n",
       "      <td>03-07-2005</td>\n",
       "      <td>09-20-2009</td>\n",
       "      <td>11.26</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  customer_name  start_date    end_date  contract_amount_m invoice_sent paid\n",
       "0          Nike  01-02-2019  12-20-2020               2.98          Yes  Yes\n",
       "1        Reebox  06-20-2017         NaN               3.90           No   No\n",
       "2        Adidas  12-07-2015   6-20-2018               4.82          Yes  Yes\n",
       "3        Google  05-25-2014  03-20-2017               5.74          Yes   No\n",
       "4        Amazon  11-10-2012  12-20-2015               6.66           No  Yes\n",
       "5      Facebook  04-29-2011         NaN               7.58          Yes   No\n",
       "6         Apple  10-15-2009         NaN               8.50          Yes  Yes\n",
       "7        Airbnb  04-02-2008         NaN               9.42           No   No\n",
       "8          Nest  09-19-2006         NaN               3.00          Yes  Yes\n",
       "9         Canon  03-07-2005  09-20-2009              11.26          Yes   No"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frames['Customer Contracts$.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db71eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_db():\n",
    "    try:\n",
    "        conn = pg.connect(host=hostname, port=port, user=username, password=password)\n",
    "    except ConnectionError as e:\n",
    "        raise e\n",
    "    else:\n",
    "        print('Connected successfully....')\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f9da80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets connect to database\n",
    "hostname='localhost'\n",
    "port='5433'\n",
    "username='gaurnitai'\n",
    "password='superuser'\n",
    "database='gaurnitai'\n",
    "conn=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ef5b4c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected successfully....\n"
     ]
    }
   ],
   "source": [
    "# conn = connect_to_db()\n",
    "# curr = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f67bd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DROP table if there are any existing table --- BE CAREFUL, may be its not needed in your case\n",
    "def drop_table(curr, table_name):\n",
    "    query = \"\"\"DROP TABLE IF EXISTS %s;\"\"\"\n",
    "    curr.execute(query % table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f251a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create table\n",
    "def create_table(curr, table_name, cols):\n",
    "    query = \"\"\"CREATE TABLE IF NOT EXISTS {} ( {} );\"\"\"\n",
    "    curr.execute(query.format(table_name, cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13f1ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data to csv and copy to database\n",
    "def copy_data_from_csv_to_db(curr, filename, tablename, dataframe):\n",
    "    dataframe.to_csv(filename, headers=dataframe.columns, index=False, encoding='UTF-8')\n",
    "    print('Saved data from df to csv...')\n",
    "    #save data from csv to db\n",
    "    my_file = open(filename)\n",
    "    print('Open file in memory...')\n",
    "    SQL_STATEMENT = \"COPY {0} FROM STDIN WITH CSV HEADER DELIMITER as ','\".format(tablename)\n",
    "    curr.copy_expert(sql=SQL_STATEMENT, file=my_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd99d920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we have file name with space and $ or there may be possibility we have unwanted characters\n",
    "# So lets remove unwanted spaces\n",
    "# remove unwanted characters\n",
    "# make lowercase\n",
    "# replace space with underscore\n",
    "for file in csv_files:\n",
    "    dataframe = data_frames[file]\n",
    "    clean_table_name = file.lower().replace(' ', '_').replace('?', '').replace('$','').replace('-','_') \\\n",
    "                    .replace('\\\\', '_').replace(r'/','_').replace(r',','_')\n",
    "    print(clean_table_name)\n",
    "    table_name = '{0}'.format(clean_table_name.split('.')[0]) # remove csv extension\n",
    "    print(table_name)\n",
    "    dataframe.columns = [x.lower().replace(' ', '_').replace('?', '').replace('$','').replace('-','_') \\\n",
    "                .replace('\\\\', '_').replace(r'/','_').replace(r',','_') for x in dataframe.columns]\n",
    "    print(dataframe.columns)\n",
    "    # replacement dict that maps pandas df dtype to sql dtype\n",
    "    replacements = {\n",
    "    'object': 'VARCHAR',\n",
    "    'float64': 'FLOAT',\n",
    "    'int64': 'INTEGER',\n",
    "    'datetime64': 'TIMESTAMP',\n",
    "    'timedelta64[ns]': 'VARCHAR'\n",
    "    }\n",
    "    col_str = ', '.join('{} {}'.format(col_name, data_type) \n",
    "                        for (col_name, data_type) in zip(dataframe.columns, \n",
    "                                                         dataframe.dtypes.replace(replacements)))\n",
    "    print(col_str)\n",
    "    conn = connect_to_db()\n",
    "    curr = conn.cursor()\n",
    "    # drop table if exist\n",
    "    drop_table(curr, table_name)\n",
    "    # create table\n",
    "    create_table(curr, table_name=table_name, cols=col_str)\n",
    "    # copy csv data to db\n",
    "    copy_data_from_csv_to_db(curr, file, table_name)\n",
    "#     conn.commit()\n",
    "#     curr.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bf6ae4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
